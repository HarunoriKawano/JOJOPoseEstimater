{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "jojo_trainer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#  jojo_trainer.ipynb\n",
        "#  3.モデルの学習を行う"
      ],
      "outputs": [],
      "metadata": {
        "id": "MQtXBAzw9mJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "QviXlRT_1Hme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/jojo_poser/src\")\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "from image_loader import *\n",
        "from models import *"
      ],
      "outputs": [],
      "metadata": {
        "id": "IL0LLAyv9ox3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"使用されるデバイス: \",device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e5DYXOg41F0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "LABELS = [\"Buccellati\", \"Dio\", \"Giorno\", \"Highway-Star\", \"Jo-suke\", \"Jo-taro\",\n",
        "            \"Kakyoin\", \"Kira\", \"Kishibe\", \"Polnareff\", \"Trish\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "W5QDtppu1F0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#  画像の読み込み\n",
        "im_rows = 256\n",
        "im_cols = 256\n",
        "\n",
        "#  Dataを取得\n",
        "root_path = \"/content/drive/MyDrive/jojo_poser\"\n",
        "train_imgs, train_labels = data_loder(root_path,\"train\", im_rows, im_cols)\n",
        "valid_imgs, valid_labels = data_loder(root_path,\"valid\", im_rows, im_cols)\n",
        "\n",
        "#  Datasetを作成\n",
        "tr_data = PreprocessJOJO(train_imgs, train_labels, \"train\")\n",
        "val_data = PreprocessJOJO(valid_imgs, valid_labels, \"valid\")\n",
        "print('訓練データのサイズ: ', tr_data.__len__())\n",
        "print('検証データのサイズ: ', val_data.__len__())\n",
        "\n",
        "#  DataLorderを作成\n",
        "batch_size = 4\n",
        "tr_batch = data.DataLoader(\n",
        "    tr_data,                #  訓練用data\n",
        "    batch_size = batch_size,#  ミニバッチのサイズ\n",
        "    shuffle = True,         #  シャッフルして抽出\n",
        "    )\n",
        "val_batch = data.DataLoader(\n",
        "    val_data,               #  検証用data\n",
        "    batch_size = batch_size,#  ミニバッチのサイズ\n",
        "    shuffle = False,        #  シャッフルはせずに抽出\n",
        "    )\n",
        "print('訓練データのミニバッチの個数: ', tr_batch.__len__())\n",
        "print('検証データのミニバッチの個数: ', val_batch.__len__())\n",
        "\n",
        "#  DataLoaderをdictにまとめる\n",
        "dataloaders_dict = {\"train\":tr_batch, \"valid\":val_batch}"
      ],
      "outputs": [],
      "metadata": {
        "id": "_McH8d7f1F0s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#  訓練用のDataLorderをイテレーターに変換\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])\n",
        "#  最初のミニバッチを取り出す\n",
        "images, labels = next(batch_iterator)\n",
        "print('ミニバッチのイメージの形状: ',images.size())\n",
        "print('ミニバッチのラベルの形状: ',len(labels))\n",
        "print('labels[0]の形状: ',labels[0].size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "-FDwg3z71F0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#   モデルのインスタンス作成\n",
        "net = JOJO_classifier('train', len(LABELS))\n",
        "#  vggモデルの学習済みの重みを適用\n",
        "vgg_weights = torch.load(root_path+'/weights/vgg16_reducedfc.pth')\n",
        "net.vgg.load_state_dict(vgg_weights)\n",
        "print(\"[model vgg] weights is applied.\")\n",
        "#  denseモデルの重みを初期化\n",
        "if isinstance(net.dense, nn.Linear):\n",
        "    init.kaiming_normal_(net.dense.weight.data)\n",
        "    if net.dense.bias is not None:\n",
        "        init.constant_(net.dense.bias, 0.0)\n",
        "\n",
        "print(net)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mcIkyZAj1F0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "summary(\n",
        "    net,\n",
        "    input_size = (batch_size, 3, im_rows, im_cols),\n",
        "    col_names=[\"input_size\",\"output_size\",\"num_params\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "GU0lBj4l1F0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "#  損失関数及びオプティマイザーの作成\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.dense.parameters(),\n",
        "                lr = 0.01,\n",
        "                weight_decay = 0.0005)"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "HR8oB5Nl1F0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "\n",
        "def train(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "    '''\n",
        "    Parameters:\n",
        "        net(object): VGG+Dense モデル\n",
        "        datalorders_dict(dict(object)): DataLorder\n",
        "        criterion(object): 損失関数\n",
        "        optimizer(object): オプティマイザー\n",
        "        num_epochs(int): 学習回数\n",
        "    '''\n",
        "    \n",
        "    net.to(device)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "    iteration = 1 #  イテレーション(ステップ)カウンター\n",
        "    epoch_train_loss = 0.0 #  訓練1エポックごとの損失和\n",
        "    epoch_val_loss = 0.0 #  検証1エポックごとの損失和\n",
        "    logs = [] #  損失のログを記録するリスト\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('----------------------------------------------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('----------------------------------------------------')\n",
        "\n",
        "        for phase in [\"train\",\"valid\"]:\n",
        "\n",
        "            if phase==\"train\":\n",
        "                #  モデルを訓練モードに\n",
        "                net.train()\n",
        "            else:\n",
        "                if((epoch+1)%10 == 0):\n",
        "                    net.eval()#  モデルを検証モードに\n",
        "                    print(\"----------------------------------------------------\")\n",
        "                    print(\"----- validation mode -----\")\n",
        "                else:\n",
        "                    continue\n",
        "                    \n",
        "            #  1ステップにおけるミニバッチを使用した学習または検証\n",
        "            #  データローダーをイテレートしてミニバッチを抽出\n",
        "            for images, labels in dataloaders_dict[phase]:\n",
        "                #  画像データにデバイスを割り当てる\n",
        "                images = images.to(device)\n",
        "                #  教師データをデバイスを割り当てる\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                #  optimizerが保持する勾配を0で初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #  順伝搬(forward)とバックプロパゲーション(訓練時)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #  順伝播(forward)\n",
        "                    outputs = net(images)\n",
        "                    #  labelの損失平均\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                    #  訓練時はバックプロパゲーションによるパラメーター更新を行う\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  #  バックプロパゲーション\n",
        "\n",
        "                        # 勾配が大きすぎると不安定になるので\n",
        "                        # clipで勾配の上限を2.0に制限する\n",
        "                        nn.utils.clip_grad_value_(net.parameters(),\n",
        "                                                  clip_value=2.0)\n",
        "                        # 勾配降下法の更新式を適用してバイアス、重みを更新\n",
        "                        optimizer.step()\n",
        "\n",
        "                        # ミニバッチを10個処理(10ステップ)ごとに損失を出力\n",
        "                        if (iteration % 10 == 0):\n",
        "                            #  ステップ, 損失を出力\n",
        "                            print('step( {} )  loss: {:.4f}'.format(iteration, loss.item()))\n",
        "\n",
        "                        # エポックの損失をepoch_train_lossに加算する\n",
        "                        epoch_train_loss += loss.item()\n",
        "                        # ステップ数を1増やす\n",
        "                        iteration += 1\n",
        "\n",
        "                    # 検証モードでは順伝播後の損失の記録のみを行う\n",
        "                    else:\n",
        "                        epoch_val_loss += loss.item()\n",
        "                        \n",
        "        # epochのphaseごとのlossと正解率\n",
        "        print('---------------------------------------')\n",
        "        # 訓練データの損失と検証データの損失を出力\n",
        "        print('train_loss: {:.4f} - val_loss(Every 10 epochs): {:.4f}'.format(epoch_train_loss, epoch_val_loss))\n",
        "\n",
        "        # エポックごとに損失をdictオブジェクトに保存\n",
        "        log_epoch = {'epoch': epoch+1,\n",
        "                     'train_loss': epoch_train_loss,\n",
        "                     'val_loss': epoch_val_loss}\n",
        "        # ログのリストに追加\n",
        "        logs.append(log_epoch)\n",
        "\n",
        "        # 訓練時の損失和を0で初期化\n",
        "        epoch_train_loss = 0.0\n",
        "        # 検証時の損失和を0で初期化\n",
        "        epoch_val_loss = 0.0\n",
        "        \n",
        "        # 1エポック終了ごとにモデルのパラメーター値を保存\n",
        "        if ((epoch+1) % 10 == 0):\n",
        "            torch.save(\n",
        "                net.state_dict(),\n",
        "                root_path + '/weights/jojo_weights' + str(epoch+1) + '.pth')\n",
        "            print('--saved weights--')\n",
        "    # ログのリストをデータフレームに変換\n",
        "    df = pd.DataFrame(logs)\n",
        "    # ログファイルに保存\n",
        "    df.to_csv(root_path + '/outputs/epoch_loss.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "X0T59dOg1F0w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#  学習\n",
        "num_epochs = 50\n",
        "train(net,\n",
        "      dataloaders_dict,\n",
        "      criterion,\n",
        "      optimizer,\n",
        "      num_epochs=num_epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8TpbxuzW1F0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "FwLXJPHj1F0y"
      }
    }
  ]
}